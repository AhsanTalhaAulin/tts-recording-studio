<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TTS Dataset Recording Studio</title>
    <!-- Material UI Fonts and Icons -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&display=swap" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons" />
    <!-- React and Material UI CDN -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/@mui/material@5.15.19/umd/material-ui.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/@emotion/react@11.11.4/dist/emotion-react.umd.min.js"></script>
    <script crossorigin src="https://unpkg.com/@emotion/styled@11.11.0/dist/emotion-styled.umd.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: 'Roboto', sans-serif;
            background-color: #f0f2f5;
        }
        #root {
            display: flex;
            justify-content: center;
            align-items: flex-start;
            min-height: 100vh;
            padding: 20px;
            box-sizing: border-box;
        }
    </style>
</head>
<body>
    <div id="root"></div>

    <!-- JSZip Library -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
    <script type="text/babel">
        const {
            AppBar, Toolbar, Typography, Button, Paper, Grid, LinearProgress, Box,
            CssBaseline, Container, createTheme, ThemeProvider, IconButton,
            Dialog, DialogTitle, DialogContent, DialogActions, TextField,
            Snackbar, Alert
        } = MaterialUI;

        const theme = createTheme({
            palette: {
                primary: {
                    main: '#4299e1', // Tailwind blue-500
                },
                secondary: {
                    main: '#cbd5e0', // Tailwind gray-300
                },
                error: {
                    main: '#e53e3e', // Tailwind red-600
                },
                success: {
                    main: '#48bb78', // Tailwind green-500
                },
                background: {
                    default: '#f0f2f5',
                    paper: '#fff',
                },
            },
            typography: {
                h4: {
                    fontWeight: 700,
                    color: '#1a202c',
                },
                h5: {
                    fontWeight: 600,
                    color: '#2d3748',
                },
                body1: {
                    fontSize: '1.1em',
                },
            },
            components: {
                MuiButton: {
                    styleOverrides: {
                        root: {
                            padding: '12px 25px',
                            fontSize: '1.1em',
                            fontWeight: 600,
                            borderRadius: '8px',
                            boxShadow: '0 4px 10px rgba(0, 0, 0, 0.1)',
                            minWidth: '120px',
                            '&:hover': {
                                transform: 'translateY(-2px)',
                                boxShadow: '0 6px 15px rgba(0, 0, 0, 0.15)',
                            },
                            '&:disabled': {
                                opacity: 0.6,
                                boxShadow: 'none',
                                transform: 'none',
                            },
                        },
                    },
                },
                MuiPaper: {
                    styleOverrides: {
                        root: {
                            borderRadius: '12px',
                            boxShadow: '0 4px 20px rgba(0, 0, 0, 0.1)',
                            padding: '30px',
                        },
                    },
                },
            },
        });

        const App = () => {
            const [conversationData, setConversationData] = React.useState([]);
            const [currentSentenceIndex, setCurrentSentenceIndex] = React.useState(0);
            const [speakerRecordings, setSpeakerRecordings] = React.useState({});
            const [uniqueSpeakers, setUniqueSpeakers] = React.useState(new Set());
            const [fileName, setFileName] = React.useState('No file selected');
            const [fileError, setFileError] = React.useState('');
            const [isRecording, setIsRecording] = React.useState(false);
            const [recordedBlob, setRecordedBlob] = React.useState(null);
            const [recordingTime, setRecordingTime] = React.useState(0);
            const [snackbarOpen, setSnackbarOpen] = React.useState(false);
            const [snackbarMessage, setSnackbarMessage] = React.useState('');
            const [snackbarSeverity, setSnackbarSeverity] = React.useState('info');

            const mediaRecorderRef = React.useRef(null);
            const audioChunksRef = React.useRef([]);
            const audioStreamRef = React.useRef(null);
            const audioContextRef = React.useRef(null);
            const analyserRef = React.useRef(null);
            const scriptProcessorRef = React.useRef(null);
            const animationFrameIdRef = React.useRef(null);
            const recordingTimerIdRef = React.useRef(null);
            const recordingTimeoutIdRef = React.useRef(null);
            const audioPlayerRef = React.useRef(null);
            const audioVisualizerRef = React.useRef(null);

            const MAX_RECORDING_DURATION = 15; // seconds
            const SAMPLE_RATE = 16000; // Target sample rate for WAV
            const BIT_DEPTH = 16; // Target bit depth for WAV (16-bit PCM)

            const showSnackbar = (message, severity = 'info') => {
                setSnackbarMessage(message);
                setSnackbarSeverity(severity);
                setSnackbarOpen(true);
            };

            const handleSnackbarClose = (event, reason) => {
                if (reason === 'clickaway') {
                    return;
                }
                setSnackbarOpen(false);
            };

            // --- Utility Functions (adapted for React state) ---

            const updateDashboardStats = React.useCallback(() => {
                let totalRecorded = 0;
                let speakerTimes = {};

                uniqueSpeakers.forEach(speaker => {
                    speakerTimes[speaker] = 0;
                    if (speakerRecordings[speaker]) {
                        totalRecorded += speakerRecordings[speaker].length;
                        speakerRecordings[speaker].forEach(rec => {
                            speakerTimes[speaker] += rec.duration || 0;
                        });
                    }
                });

                // This would typically update state variables that are then rendered
                // For now, we'll just log or assume a re-render will pick up changes
                // if these were part of a larger state object.
                // For a full React app, these would be state variables.
                // Example: setDashboardStats({ totalRecorded, speakerTimes });
            }, [speakerRecordings, uniqueSpeakers]);

            const audioBufferToWav = (audioBuffer) => {
                const numOfChan = audioBuffer.numberOfChannels;
                const length = audioBuffer.length * numOfChan;
                const result = new Float32Array(length);
                for (let i = 0; i < numOfChan; i++) {
                    audioBuffer.getChannelData(i).forEach((sample, index) => {
                        result[index * numOfChan + i] = sample;
                    });
                }

                const buffer = new ArrayBuffer(44 + result.length * 2);
                const view = new DataView(buffer);

                const writeString = (view, offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };

                const floatTo16BitPCM = (output, offset, input) => {
                    for (let i = 0; i < input.length; i++, offset += 2) {
                        const s = Math.max(-1, Math.min(1, input[i]));
                        output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                    }
                };

                writeString(view, 0, 'RIFF');
                view.setUint32(4, 36 + result.length * 2, true);
                writeString(view, 8, 'WAVE');
                writeString(view, 12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, numOfChan, true);
                view.setUint32(24, audioBuffer.sampleRate, true);
                view.setUint32(28, audioBuffer.sampleRate * numOfChan * (BIT_DEPTH / 8), true);
                view.setUint16(32, numOfChan * (BIT_DEPTH / 8), true);
                view.setUint16(34, BIT_DEPTH, true);
                writeString(view, 36, 'data');
                view.setUint32(40, result.length * 2, true);

                floatTo16BitPCM(view, 44, result);

                return new Blob([view], { type: 'audio/wav' });
            };

            const resampleAudioBuffer = async (audioBuffer, targetSampleRate) => {
                if (audioBuffer.sampleRate === targetSampleRate) {
                    return audioBuffer;
                }

                const offlineContext = new OfflineAudioContext(
                    audioBuffer.numberOfChannels,
                    audioBuffer.duration * targetSampleRate,
                    targetSampleRate
                );

                const source = offlineContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(offlineContext.destination);
                source.start(0);

                return offlineContext.startRendering();
            };

            // --- Core Modules (adapted for React state and refs) ---

            const parseAndValidateJSON = async (jsonString) => {
                let parsedData;
                try {
                    parsedData = JSON.parse(jsonString);
                } catch (e) {
                    throw new Error("Invalid JSON format.");
                }

                let tempConversation = [];
                if (Array.isArray(parsedData)) {
                    tempConversation = parsedData;
                } else if (typeof parsedData === 'object' && parsedData !== null && Array.isArray(parsedData.conversation)) {
                    tempConversation = parsedData.conversation;
                } else {
                    throw new Error("Unsupported JSON structure. Expected an array of objects or an object with a 'conversation' array.");
                }

                if (tempConversation.length === 0) {
                    throw new Error("JSON contains no conversation entries.");
                }

                const newUniqueSpeakers = new Set();
                for (const entry of tempConversation) {
                    if (typeof entry.speaker !== 'string' || entry.speaker.trim() === '') {
                        throw new Error("Each conversation entry must have a non-empty 'speaker' string.");
                    }
                    if (typeof entry.text !== 'string' || entry.text.trim() === '') {
                        throw new Error("Each conversation entry must have a non-empty 'text' string.");
                    }
                    newUniqueSpeakers.add(entry.speaker.trim());
                }

                setConversationData(prevData => {
                    const startIndex = prevData.length;
                    const newSentences = tempConversation.map((entry, index) => ({
                        ...entry,
                        speaker: entry.speaker.trim(),
                        text: entry.text.trim(),
                        id: String(startIndex + index + 1).padStart(4, '0')
                    }));
                    return [...prevData, ...newSentences];
                });

                setUniqueSpeakers(prevSpeakers => {
                    const updatedSpeakers = new Set(prevSpeakers);
                    newUniqueSpeakers.forEach(speaker => {
                        updatedSpeakers.add(speaker);
                        setSpeakerRecordings(prevRecs => ({
                            ...prevRecs,
                            [speaker]: prevRecs[speaker] || []
                        }));
                    });
                    return updatedSpeakers;
                });

                if (conversationData.length === 0) {
                    setCurrentSentenceIndex(0);
                }
            };

            const handleFileUpload = async (event) => {
                const file = event.target.files[0];
                if (!file) {
                    setFileName('No file selected');
                    setFileError('');
                    setConversationData([]);
                    setCurrentSentenceIndex(0);
                    setSpeakerRecordings({});
                    setUniqueSpeakers(new Set());
                    return;
                }

                setFileName(file.name);
                setFileError('');

                const reader = new FileReader();
                reader.onload = async (e) => {
                    try {
                        const jsonString = e.target.result;
                        await parseAndValidateJSON(jsonString);
                        showSnackbar('JSON file loaded successfully!', 'success');
                    } catch (error) {
                        console.error("File processing error:", error);
                        setFileError(`Error parsing JSON: ${error.message}. Please ensure it's a valid JSON file with the correct structure.`);
                        setConversationData([]);
                        setCurrentSentenceIndex(0);
                        setSpeakerRecordings({});
                        setUniqueSpeakers(new Set());
                        showSnackbar(`Error loading file: ${error.message}`, 'error');
                    }
                };
                reader.onerror = () => {
                    setFileError('Failed to read file.');
                    setConversationData([]);
                    setCurrentSentenceIndex(0);
                    setSpeakerRecordings({});
                    setUniqueSpeakers(new Set());
                    showSnackbar('Failed to read file.', 'error');
                };
                reader.readAsText(file);
            };

            const startRecording = async () => {
                // Stop any currently playing audio
                if (audioPlayerRef.current) {
                    audioPlayerRef.current.pause();
                    audioPlayerRef.current.currentTime = 0;
                }

                audioChunksRef.current = [];
                setRecordedBlob(null);
                setRecordingTime(0);
                setIsRecording(true);

                try {
                    if (!audioStreamRef.current || !audioStreamRef.current.active) {
                        audioStreamRef.current = await navigator.mediaDevices.getUserMedia({
                            audio: {
                                echoCancellation: true,
                                noiseSuppression: true,
                                autoGainControl: false,
                                sampleRate: SAMPLE_RATE,
                                channelCount: 1
                            }
                        });

                        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
                        analyserRef.current = audioContextRef.current.createAnalyser();
                        const microphone = audioContextRef.current.createMediaStreamSource(audioStreamRef.current);
                        scriptProcessorRef.current = audioContextRef.current.createScriptProcessor(1024, 1, 1);

                        analyserRef.current.fftSize = 1024;
                        const bufferLength = analyserRef.current.frequencyBinCount;
                        const dataArray = new Uint8Array(bufferLength);

                        microphone.connect(analyserRef.current);
                        analyserRef.current.connect(scriptProcessorRef.current);
                        scriptProcessorRef.current.connect(audioContextRef.current.destination);

                        const canvas = audioVisualizerRef.current;
                        const canvasCtx = canvas.getContext('2d');
                        canvas.width = canvas.offsetWidth;
                        canvas.height = canvas.offsetHeight;

                        const draw = () => {
                            animationFrameIdRef.current = requestAnimationFrame(draw);
                            analyserRef.current.getByteTimeDomainData(dataArray);
                            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
                            canvasCtx.lineWidth = 2;
                            canvasCtx.strokeStyle = theme.palette.primary.main;
                            canvasCtx.beginPath();

                            const sliceWidth = canvas.width * 1.0 / bufferLength;
                            let x = 0;

                            for (let i = 0; i < bufferLength; i++) {
                                const v = dataArray[i] / 128.0;
                                const y = v * canvas.height * 0.75;

                                if (i === 0) {
                                    canvasCtx.moveTo(x, y);
                                } else {
                                    canvasCtx.lineTo(x, y);
                                }
                                x += sliceWidth;
                            }
                            canvasCtx.lineTo(canvas.width, canvas.height / 2);
                            canvasCtx.stroke();
                        };
                        draw();
                    }

                    mediaRecorderRef.current = new MediaRecorder(audioStreamRef.current, {
                        mimeType: 'audio/webm;codecs=opus'
                    });

                    mediaRecorderRef.current.ondataavailable = (event) => {
                        audioChunksRef.current.push(event.data);
                    };

                    mediaRecorderRef.current.onstop = () => {
                        setIsRecording(false);
                        cancelAnimationFrame(animationFrameIdRef.current);
                        clearInterval(recordingTimerIdRef.current);
                        clearTimeout(recordingTimeoutIdRef.current);

                        if (audioStreamRef.current) {
                            audioStreamRef.current.getTracks().forEach(track => track.stop());
                            audioStreamRef.current = null;
                        }
                        if (audioContextRef.current) {
                            audioContextRef.current.close();
                            audioContextRef.current = null;
                        }

                        const blob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
                        setRecordedBlob(blob);
                        playRecording(blob); // Play immediately after stop
                    };

                    mediaRecorderRef.current.start();
                    const recordingStartTime = Date.now();
                    recordingTimerIdRef.current = setInterval(() => {
                        setRecordingTime(((Date.now() - recordingStartTime) / 1000));
                    }, 100);

                    recordingTimeoutIdRef.current = setTimeout(() => {
                        stopRecording();
                        showSnackbar('Recording auto-stopped after 15 seconds.', 'info');
                    }, MAX_RECORDING_DURATION * 1000);

                } catch (err) {
                    console.error('Error accessing microphone:', err);
                    setFileError('Could not access microphone. Please ensure it is connected and permissions are granted.');
                    setIsRecording(false);
                    cancelAnimationFrame(animationFrameIdRef.current);
                    clearInterval(recordingTimerIdRef.current);
                    clearTimeout(recordingTimeoutIdRef.current);
                    showSnackbar('Microphone access denied or error.', 'error');
                }
            };

            const stopRecording = () => {
                if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
                    mediaRecorderRef.current.stop();
                }
            };

            const playRecording = (blobToPlay = recordedBlob) => {
                if (blobToPlay) {
                    const audioUrl = URL.createObjectURL(blobToPlay);
                    audioPlayerRef.current.src = audioUrl;
                    audioPlayerRef.current.play();
                    audioPlayerRef.current.onended = () => {
                        URL.revokeObjectURL(audioUrl);
                    };
                } else {
                    console.warn("No audio to play.");
                    showSnackbar('No audio recorded to play.', 'warning');
                }
            };

            const acceptRecording = async () => {
                if (!recordedBlob) {
                    console.warn("No audio recorded to accept.");
                    showSnackbar('No audio recorded to accept.', 'warning');
                    return;
                }

                const currentEntry = conversationData[currentSentenceIndex];

                try {
                    const audioBuffer = await new Promise((resolve, reject) => {
                        const reader = new FileReader();
                        reader.onload = (e) => {
                            const tempAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                            tempAudioContext.decodeAudioData(e.target.result, resolve, reject);
                        };
                        reader.onerror = reject;
                        reader.readAsArrayBuffer(recordedBlob);
                    });

                    const resampledBuffer = await resampleAudioBuffer(audioBuffer, SAMPLE_RATE);
                    const wavBlob = audioBufferToWav(resampledBuffer);

                    const formData = new FormData();
                    formData.append('speaker_name', currentEntry.speaker);
                    formData.append('text', currentEntry.text);
                    formData.append('audio_file', wavBlob, `${currentEntry.id}.wav`);

                    const response = await fetch('/upload-recording', {
                        method: 'POST',
                        body: formData,
                    });

                    if (response.ok) {
                        const result = await response.json();
                        console.log('Recording successfully uploaded:', result);

                        setSpeakerRecordings(prevRecs => {
                            const updatedRecs = { ...prevRecs };
                            if (!updatedRecs[currentEntry.speaker]) {
                                updatedRecs[currentEntry.speaker] = [];
                            }
                            updatedRecs[currentEntry.speaker].push({
                                id: currentEntry.id,
                                blob: wavBlob,
                                text: currentEntry.text,
                                duration: resampledBuffer.duration
                            });
                            return updatedRecs;
                        });

                        setCurrentSentenceIndex(prevIndex => prevIndex + 1);
                        setRecordedBlob(null); // Clear recorded blob after acceptance
                        showSnackbar('Recording accepted and uploaded!', 'success');
                    } else {
                        const errorData = await response.json();
                        console.error('Failed to upload recording:', errorData);
                        setFileError(`Upload failed: ${errorData.detail || response.statusText}. Please try again.`);
                        showSnackbar(`Upload failed: ${errorData.detail || response.statusText}`, 'error');
                    }
                } catch (error) {
                    console.error("Error processing or uploading audio:", error);
                    setFileError("Failed to process and accept audio. Please try re-recording.");
                    showSnackbar('Failed to process and accept audio.', 'error');
                }
            };

            const skipSentence = () => {
                setCurrentSentenceIndex(prevIndex => prevIndex + 1);
                setRecordedBlob(null); // Clear recorded blob on skip
                showSnackbar('Sentence skipped.', 'info');
            };

            const generateExportButtons = React.useCallback(() => {
                return Array.from(uniqueSpeakers).map(speaker => {
                    const recordingsForSpeaker = speakerRecordings[speaker] || [];
                    return (
                        <Button
                            key={speaker}
                            variant="contained"
                            color="primary"
                            onClick={() => exportSpeakerRecordings(speaker)}
                            disabled={recordingsForSpeaker.length === 0}
                            sx={{ m: 1 }}
                        >
                            Export {speaker} Recordings
                        </Button>
                    );
                });
            }, [uniqueSpeakers, speakerRecordings]);

            const exportSpeakerRecordings = async (speakerName) => {
                const zip = new JSZip();
                const speakerData = speakerRecordings[speakerName];

                if (!speakerData || speakerData.length === 0) {
                    showSnackbar(`No recordings found for ${speakerName}.`, 'warning');
                    return;
                }

                let txtContent = '';
                speakerData.forEach(rec => {
                    txtContent += `${rec.id}|${rec.text}\n`;
                });
                zip.file(`${speakerName}.txt`, txtContent);

                const speakerFolder = zip.folder(speakerName);
                for (const rec of speakerData) {
                    speakerFolder.file(`${rec.id}.wav`, rec.blob);
                }

                try {
                    const zipBlob = await zip.generateAsync({ type: "blob" });
                    const downloadLink = document.createElement('a');
                    downloadLink.href = URL.createObjectURL(zipBlob);
                    downloadLink.download = `${speakerName}_tts_dataset.zip`;
                    document.body.appendChild(downloadLink);
                    downloadLink.click();
                    document.body.removeChild(downloadLink);
                    URL.revokeObjectURL(downloadLink.href);
                    showSnackbar(`Exported ${speakerName} recordings!`, 'success');
                } catch (error) {
                    console.error("Error generating ZIP:", error);
                    showSnackbar("Failed to create ZIP archive. Please try again.", 'error');
                }
            };

            // Keyboard shortcuts
            React.useEffect(() => {
                const handleKeyPress = (event) => {
                    if (event.code === 'Space') {
                        event.preventDefault(); // Prevent scrolling
                        if (isRecording) {
                            stopRecording();
                        } else if (conversationData.length > 0 && currentSentenceIndex < conversationData.length) {
                            startRecording();
                        }
                    } else if (event.code === 'Enter') {
                        if (recordedBlob && !isRecording) {
                            acceptRecording();
                        }
                    }
                };

                document.addEventListener('keydown', handleKeyPress);
                return () => {
                    document.removeEventListener('keydown', handleKeyPress);
                };
            }, [isRecording, recordedBlob, conversationData, currentSentenceIndex]); // Dependencies for effect

            // Update dashboard stats whenever relevant state changes
            React.useEffect(() => {
                updateDashboardStats();
            }, [conversationData, speakerRecordings, uniqueSpeakers, updateDashboardStats]);

            const currentEntry = conversationData[currentSentenceIndex];
            const progress = conversationData.length > 0 ? (currentSentenceIndex / conversationData.length) * 100 : 0;

            return (
                <ThemeProvider theme={theme}>
                    <CssBaseline />
                    <Container maxWidth="md" sx={{ mt: 4, mb: 4 }}>
                        <AppBar position="static" color="transparent" elevation={0} sx={{ mb: 3 }}>
                            <Toolbar component={Paper} sx={{ borderRadius: '12px', p: 2, display: 'flex', flexWrap: 'wrap', justifyContent: 'space-between', alignItems: 'center', gap: 2 }}>
                                <Typography variant="h4" component="h1" sx={{ flexGrow: 1, textAlign: { xs: 'center', md: 'left' } }}>
                                    TTS Dataset Recording Studio
                                </Typography>
                                <Box sx={{ display: 'flex', flexWrap: 'wrap', gap: 1.5, justifyContent: { xs: 'center', md: 'flex-start' }, flexGrow: 2 }}>
                                    <Paper elevation={1} sx={{ p: '8px 12px', textAlign: 'center', minWidth: '100px' }}>
                                        <Typography variant="caption" display="block" color="text.secondary">Total Sentences</Typography>
                                        <Typography variant="subtitle1" color="primary.dark">{conversationData.length}</Typography>
                                    </Paper>
                                    <Paper elevation={1} sx={{ p: '8px 12px', textAlign: 'center', minWidth: '100px' }}>
                                        <Typography variant="caption" display="block" color="text.secondary">Recorded</Typography>
                                        <Typography variant="subtitle1" color="primary.dark">
                                            {Object.values(speakerRecordings).reduce((acc, val) => acc + val.length, 0)}
                                        </Typography>
                                    </Paper>
                                    {Array.from(uniqueSpeakers).map(speaker => (
                                        <Paper key={speaker} elevation={1} sx={{ p: '8px 12px', textAlign: 'center', minWidth: '100px' }}>
                                            <Typography variant="caption" display="block" color="text.secondary">{speaker} Time</Typography>
                                            <Typography variant="subtitle1" color="primary.dark">
                                                {(speakerRecordings[speaker] || []).reduce((acc, rec) => acc + rec.duration, 0).toFixed(1)}s
                                            </Typography>
                                        </Paper>
                                    ))}
                                </Box>
                                <Box sx={{ display: 'flex', flexDirection: 'column', alignItems: { xs: 'center', md: 'flex-end' }, gap: 0.5 }}>
                                    <Button
                                        variant="outlined"
                                        component="label"
                                        startIcon={<MaterialUI.Icon>upload_file</MaterialUI.Icon>}
                                        sx={{ borderColor: 'secondary.main', bgcolor: 'background.default', '&:hover': { borderColor: 'primary.main', bgcolor: 'primary.light' } }}
                                    >
                                        Upload JSON
                                        <input type="file" hidden accept=".json" onChange={handleFileUpload} />
                                    </Button>
                                    <Typography variant="caption" color="text.secondary" sx={{ textAlign: 'right', maxWidth: '150px', overflow: 'hidden', textOverflow: 'ellipsis', whiteSpace: 'nowrap' }}>
                                        {fileName}
                                    </Typography>
                                    {fileError && (
                                        <Typography variant="caption" color="error.main" sx={{ textAlign: 'right', width: '100%' }}>
                                            {fileError}
                                        </Typography>
                                    )}
                                </Box>
                            </Toolbar>
                        </AppBar>

                        {conversationData.length > 0 && currentSentenceIndex < conversationData.length && (
                            <Paper sx={{ p: 3, mb: 3 }}>
                                <Typography variant="h5" sx={{ mb: 2, pb: 1, borderBottom: '2px solid', borderColor: 'divider' }}>
                                    Record Audio
                                </Typography>
                                <Box sx={{ display: 'flex', flexDirection: 'column', gap: 2, alignItems: 'center' }}>
                                    <Typography variant="h6" color="primary.dark">
                                        Speaker: {currentEntry.speaker}
                                    </Typography>
                                    <Paper variant="outlined" sx={{ p: 2, width: '100%', textAlign: 'center', fontSize: '1.2em', lineHeight: 1.5, bgcolor: 'grey.50' }}>
                                        {currentEntry.text}
                                    </Paper>

                                    <Box sx={{ width: '100%', mt: 1 }}>
                                        <LinearProgress variant="determinate" value={progress} sx={{ height: 15, borderRadius: 10, bgcolor: 'grey.300', '& .MuiLinearProgress-bar': { borderRadius: 10, bgcolor: 'primary.main' } }} />
                                        <Typography variant="body2" color="text.secondary" sx={{ textAlign: 'center', mt: 0.5 }}>
                                            {currentSentenceIndex}/{conversationData.length}
                                        </Typography>
                                    </Box>

                                    <canvas ref={audioVisualizerRef} style={{ width: '100%', maxWidth: '600px', height: '80px', background: theme.palette.grey[200], borderRadius: '8px', border: `1px solid ${theme.palette.grey[400]}` }}></canvas>
                                    {isRecording && (
                                        <Typography variant="body1" color="text.secondary" sx={{ fontWeight: 600 }}>
                                            Time: {recordingTime.toFixed(1)}s / {MAX_RECORDING_DURATION}s
                                        </Typography>
                                    )}

                                    <Box sx={{ display: 'flex', flexWrap: 'wrap', justifyContent: 'center', gap: 1.5, width: '100%' }}>
                                        <Button
                                            variant="contained"
                                            color={isRecording ? "error" : "primary"}
                                            onClick={isRecording ? stopRecording : startRecording}
                                            disabled={!conversationData.length || currentSentenceIndex >= conversationData.length}
                                        >
                                            {isRecording ? 'Stop Recording' : 'Start Recording'}
                                        </Button>
                                        <Button
                                            variant="contained"
                                            color="secondary"
                                            onClick={() => playRecording()}
                                            disabled={!recordedBlob || isRecording}
                                        >
                                            Play Recording
                                        </Button>
                                        <Button
                                            variant="contained"
                                            color="success"
                                            onClick={acceptRecording}
                                            disabled={!recordedBlob || isRecording}
                                        >
                                            Accept
                                        </Button>
                                        <Button
                                            variant="contained"
                                            color="secondary"
                                            onClick={skipSentence}
                                            disabled={isRecording}
                                        >
                                            Skip
                                        </Button>
                                    </Box>
                                </Box>
                            </Paper>
                        )}

                        {conversationData.length > 0 && currentSentenceIndex >= conversationData.length && (
                            <Paper sx={{ p: 3, mb: 3, textAlign: 'center' }}>
                                <Typography variant="h5" sx={{ mb: 2, pb: 1, borderBottom: '2px solid', borderColor: 'divider' }}>
                                    Export Recordings
                                </Typography>
                                <Typography variant="h6" color="success.main" sx={{ mb: 2 }}>
                                    All sentences recorded! Ready to export.
                                </Typography>
                                <Box sx={{ display: 'flex', flexWrap: 'wrap', justifyContent: 'center', gap: 1.5 }}>
                                    {generateExportButtons()}
                                </Box>
                            </Paper>
                        )}

                        <audio ref={audioPlayerRef} style={{ display: 'none' }}></audio>
                    </Container>
                    <Snackbar open={snackbarOpen} autoHideDuration={6000} onClose={handleSnackbarClose}>
                        <Alert onClose={handleSnackbarClose} severity={snackbarSeverity} sx={{ width: '100%' }}>
                            {snackbarMessage}
                        </Alert>
                    </Snackbar>
                </ThemeProvider>
            );
        };

        ReactDOM.render(<App />, document.getElementById('root'));
    </script>
</body>
</html>
